{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwDJmVl1aQiuJ2IKpg8qu6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saktiworkstation/reinforcement-learning-as-a-character/blob/main/Dynamic_Character_Evolution_v_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pastikan dependensi terinstall\n",
        "# ok"
      ],
      "metadata": {
        "id": "2NKefl817NTY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Msdkt7E46Hbq",
        "outputId": "dc0387ca-efdc-4235-e4a3-13265d211251"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mulai pelatihan modul RL...\n",
            "[RL] Episode 0/500, Loss: -1.4577\n",
            "[RL] Episode 200/500, Loss: 0.0013\n",
            "[RL] Episode 400/500, Loss: 0.0001\n",
            "\n",
            "Mulai pelatihan modul NLP...\n",
            "[NLP] Epoch 1/3, Loss: 6.2187\n",
            "[NLP] Epoch 2/3, Loss: 6.1673\n",
            "[NLP] Epoch 3/3, Loss: 6.1264\n",
            "\n",
            "Mulai pelatihan modul CNN...\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:04<00:00, 41.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "[CNN] Epoch 1/1, Batch 0, Loss: 2.3018\n",
            "[CNN] Epoch 1/1, Batch 100, Loss: 1.7802\n",
            "[CNN] Epoch 1/1, Batch 200, Loss: 1.5083\n",
            "[CNN] Epoch 1/1, Batch 300, Loss: 1.4672\n",
            "[CNN] Epoch 1/1, Batch 400, Loss: 1.4815\n",
            "[CNN] Epoch 1/1, Batch 500, Loss: 1.1563\n",
            "[CNN] Epoch 1/1, Batch 600, Loss: 1.2887\n",
            "[CNN] Epoch 1/1, Batch 700, Loss: 1.3157\n",
            "Selesai melatih CNN.\n",
            "\n",
            "Mulai pelatihan Dynamic Character (integrasi)...\n",
            "[DynamicCharacter] Epoch 1/3, Loss: 0.9204\n",
            "[DynamicCharacter] Epoch 2/3, Loss: 0.1407\n",
            "[DynamicCharacter] Epoch 3/3, Loss: 0.1287\n",
            "\n",
            "Model telah disimpan sebagai dynamic_character_model.nn\n"
          ]
        }
      ],
      "source": [
        "# Pastikan menjalankan di Google Colab dengan runtime GPU jika memungkinkan\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Categorical\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# Set seed untuk reproduktifitas\n",
        "seed = 42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "\n",
        "#########################\n",
        "# 1. Adaptive Personality Engine (RL)\n",
        "#########################\n",
        "\n",
        "class PolicyNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    Jaringan untuk mempelajari strategi karakter berdasarkan state\n",
        "    Menggunakan Fully Connected Layers untuk menghasilkan distribusi probabilitas atas aksi.\n",
        "    \"\"\"\n",
        "    def __init__(self, state_size, action_size, hidden_size=128):\n",
        "        super(PolicyNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(state_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.action_head = nn.Linear(hidden_size, action_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        action_probs = F.softmax(self.action_head(x), dim=-1)\n",
        "        return action_probs\n",
        "\n",
        "def train_rl_policy(policy_net, optimizer, episodes=1000, gamma=0.99):\n",
        "    \"\"\"\n",
        "    Simulasi pelatihan RL dengan data dummy:\n",
        "    - Menghasilkan state acak\n",
        "    - Memilih aksi berdasarkan policy network\n",
        "    - Mendapatkan reward dummy (misalnya reward positif jika aksi tertentu diambil)\n",
        "    - Melakukan update policy dengan REINFORCE algorithm\n",
        "    \"\"\"\n",
        "    policy_net.train()\n",
        "    for episode in range(episodes):\n",
        "        # Dummy state: vektor acak\n",
        "        state = torch.FloatTensor(np.random.rand(1, 10))\n",
        "        probs = policy_net(state)\n",
        "        m = Categorical(probs)\n",
        "        action = m.sample()\n",
        "\n",
        "        # Dummy reward: misal, reward positif jika aksi 0 diambil\n",
        "        reward = 1.0 if action.item() == 0 else -1.0\n",
        "\n",
        "        # Hitung loss berdasarkan REINFORCE: -log(prob) * reward\n",
        "        loss = -m.log_prob(action) * reward\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if episode % 200 == 0:\n",
        "            print(f\"[RL] Episode {episode}/{episodes}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "#########################\n",
        "# 2. Conversational Intelligence (NLP)\n",
        "#########################\n",
        "\n",
        "class ConversationalModule(nn.Module):\n",
        "    \"\"\"\n",
        "    Modul NLP sederhana menggunakan embedding dan LSTM untuk menghasilkan respons percakapan.\n",
        "    Data input berupa indeks token, dan model menghasilkan distribusi kata berikutnya.\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embed_size=64, hidden_size=128, num_layers=1):\n",
        "        super(ConversationalModule, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, input_seq, hidden=None):\n",
        "        embeds = self.embedding(input_seq)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "        output = self.fc(lstm_out)\n",
        "        return output, hidden\n",
        "\n",
        "def train_conversational_module(conv_module, optimizer, vocab_size, epochs=5):\n",
        "    \"\"\"\n",
        "    Simulasi pelatihan modul percakapan dengan data dummy:\n",
        "    - Input berupa urutan token acak\n",
        "    - Target adalah pergeseran urutan token (next word prediction)\n",
        "    \"\"\"\n",
        "    conv_module.train()\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    # Dummy dataset: 100 sequence, panjang 10\n",
        "    num_sequences = 100\n",
        "    seq_length = 10\n",
        "    inputs = torch.randint(0, vocab_size, (num_sequences, seq_length))\n",
        "    targets = torch.roll(inputs, shifts=-1, dims=1)  # target adalah pergeseran 1 posisi\n",
        "\n",
        "    dataset = TensorDataset(inputs, targets)\n",
        "    loader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "        for input_seq, target_seq in loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs, _ = conv_module(input_seq)\n",
        "            # reshape outputs dan target untuk CrossEntropyLoss: (batch*seq, vocab_size) vs (batch*seq)\n",
        "            loss = loss_fn(outputs.view(-1, vocab_size), target_seq.view(-1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"[NLP] Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(loader):.4f}\")\n",
        "\n",
        "#########################\n",
        "# 3. Visual Perception and Learning (CNN)\n",
        "#########################\n",
        "\n",
        "class VisualPerceptionCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    CNN untuk pengenalan elemen visual. Contoh arsitektur sederhana untuk klasifikasi.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(VisualPerceptionCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
        "        self.fc1 = nn.Linear(32 * 8 * 8, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))  # Output: [batch, 16, 16, 16] (misalnya input 32x32)\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # Output: [batch, 32, 8, 8]\n",
        "        x = x.view(-1, 32 * 8 * 8)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def train_visual_cnn(cnn_module, optimizer, epochs=3):\n",
        "    \"\"\"\n",
        "    Pelatihan CNN menggunakan dataset CIFAR-10 sebagai contoh.\n",
        "    Dataset diunduh secara otomatis oleh torchvision.\n",
        "    \"\"\"\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
        "    trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "    trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    cnn_module.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = cnn_module(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            if i % 100 == 0:\n",
        "                print(f\"[CNN] Epoch {epoch+1}/{epochs}, Batch {i}, Loss: {loss.item():.4f}\")\n",
        "    print(\"Selesai melatih CNN.\")\n",
        "\n",
        "#########################\n",
        "# 4. Real-Time Evolution Engine (Integrasi Semua Modul)\n",
        "#########################\n",
        "\n",
        "class DynamicCharacter(nn.Module):\n",
        "    \"\"\"\n",
        "    Integrasi dari ketiga modul utama.\n",
        "    - Menggunakan fitur state dari PolicyNetwork untuk adaptasi perilaku\n",
        "    - Fitur NLP untuk dialog kontekstual\n",
        "    - Fitur visual dari CNN untuk analisis lingkungan\n",
        "    Output akhir berupa vektor representasi kepribadian yang dapat digunakan untuk menentukan respon/aksi.\n",
        "    \"\"\"\n",
        "    def __init__(self, state_size, action_size, vocab_size, num_classes):\n",
        "        super(DynamicCharacter, self).__init__()\n",
        "        self.policy_net = PolicyNetwork(state_size, action_size)\n",
        "        self.conv_module = ConversationalModule(vocab_size)\n",
        "        self.visual_module = VisualPerceptionCNN(num_classes)\n",
        "        # Layer integrasi (fusion) dari fitur-fitur yang diperoleh\n",
        "        self.fc_fusion = nn.Linear(128 + 128 + 128, 256)\n",
        "        self.fc_out = nn.Linear(256, action_size)  # Output dapat diinterpretasikan sebagai sinyal adaptasi strategi\n",
        "\n",
        "    def forward(self, state, text_seq, image):\n",
        "        # Dapatkan fitur dari masing-masing modul\n",
        "        # 1. RL: Ambil fitur dari hidden layer sebelum output akhir\n",
        "        rl_feat = F.relu(self.policy_net.fc1(state))\n",
        "\n",
        "        # 2. NLP: Ambil hidden state dari LSTM (gunakan token pertama sebagai representasi)\n",
        "        embeds = self.conv_module.embedding(text_seq)\n",
        "        lstm_out, (hn, cn) = self.conv_module.lstm(embeds)\n",
        "        nlp_feat = hn[-1]  # ambil hidden state dari layer terakhir\n",
        "\n",
        "        # 3. Visual: Ambil fitur dari CNN (dari fc1)\n",
        "        x = F.relu(self.visual_module.conv1(image))\n",
        "        x = self.visual_module.pool(x)\n",
        "        x = F.relu(self.visual_module.conv2(x))\n",
        "        x = self.visual_module.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        visual_feat = F.relu(self.visual_module.fc1(x))\n",
        "\n",
        "        # Fusion: Gabungkan ketiga fitur (asumsi dimensi disesuaikan)\n",
        "        combined = torch.cat([rl_feat, nlp_feat, visual_feat], dim=1)\n",
        "        fusion = F.relu(self.fc_fusion(combined))\n",
        "        output = self.fc_out(fusion)\n",
        "        return output\n",
        "\n",
        "#########################\n",
        "# 5. Simulasi Pelatihan dan Export Model\n",
        "#########################\n",
        "\n",
        "def train_dynamic_character(model, epochs=3):\n",
        "    \"\"\"\n",
        "    Simulasi pelatihan gabungan dengan dummy data untuk masing-masing input:\n",
        "    - state: vektor acak\n",
        "    - text_seq: urutan token acak\n",
        "    - image: citra acak (sesuaikan dengan ukuran yang diperlukan oleh CNN)\n",
        "    \"\"\"\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    loss_fn = nn.MSELoss()  # Dummy loss, misal: perbedaan antara output dan target dummy\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        # Buat dummy input\n",
        "        batch_size = 16\n",
        "        state = torch.FloatTensor(np.random.rand(batch_size, 10))\n",
        "        text_seq = torch.randint(0, 500, (batch_size, 10))  # vocab_size diasumsikan 500\n",
        "        image = torch.randn(batch_size, 3, 32, 32)  # ukuran gambar 32x32\n",
        "        target = torch.FloatTensor(np.random.rand(batch_size, model.fc_out.out_features))\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(state, text_seq, image)\n",
        "        loss = loss_fn(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(f\"[DynamicCharacter] Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")\n",
        "\n",
        "# Inisialisasi parameter\n",
        "state_size = 10\n",
        "action_size = 4   # misal, 4 kemungkinan aksi/perilaku\n",
        "vocab_size = 500  # untuk modul NLP\n",
        "num_classes = 10  # untuk CNN, misal klasifikasi 10 kelas\n",
        "\n",
        "# Inisialisasi masing-masing optimizer untuk modul RL, NLP, dan CNN\n",
        "policy_net = PolicyNetwork(state_size, action_size)\n",
        "optimizer_rl = optim.Adam(policy_net.parameters(), lr=0.001)\n",
        "\n",
        "conv_module = ConversationalModule(vocab_size)\n",
        "optimizer_nlp = optim.Adam(conv_module.parameters(), lr=0.001)\n",
        "\n",
        "visual_module = VisualPerceptionCNN(num_classes)\n",
        "optimizer_cnn = optim.Adam(visual_module.parameters(), lr=0.001)\n",
        "\n",
        "# Latih masing-masing modul secara terpisah\n",
        "print(\"Mulai pelatihan modul RL...\")\n",
        "train_rl_policy(policy_net, optimizer_rl, episodes=500)\n",
        "\n",
        "print(\"\\nMulai pelatihan modul NLP...\")\n",
        "train_conversational_module(conv_module, optimizer_nlp, vocab_size, epochs=3)\n",
        "\n",
        "print(\"\\nMulai pelatihan modul CNN...\")\n",
        "train_visual_cnn(visual_module, optimizer_cnn, epochs=1)  # gunakan 1 epoch untuk simulasi cepat\n",
        "\n",
        "# Integrasi ke dalam model DynamicCharacter\n",
        "dynamic_character = DynamicCharacter(state_size, action_size, vocab_size, num_classes)\n",
        "# Salin bobot masing-masing modul yang sudah dilatih ke dalam model integrasi\n",
        "dynamic_character.policy_net.load_state_dict(policy_net.state_dict())\n",
        "dynamic_character.conv_module.load_state_dict(conv_module.state_dict())\n",
        "dynamic_character.visual_module.load_state_dict(visual_module.state_dict())\n",
        "\n",
        "print(\"\\nMulai pelatihan Dynamic Character (integrasi)...\")\n",
        "train_dynamic_character(dynamic_character, epochs=3)\n",
        "\n",
        "# Simpan model akhir ke file dengan ekstensi .nn\n",
        "model_filename = \"dynamic_character_model.nn\"\n",
        "torch.save(dynamic_character.state_dict(), model_filename)\n",
        "print(f\"\\nModel telah disimpan sebagai {model_filename}\")"
      ]
    }
  ]
}