{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3XuhQT59Ke5rwYwN4vSdk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saktiworkstation/reinforcement-learning-as-a-character/blob/main/Survival_Quest_V_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICh7L_Gn-LKE",
        "outputId": "5008ede5-0999-464f-ab25-5082b2776c57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from gym) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym) (3.1.1)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install gym pygame"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "from gym import spaces\n",
        "import numpy as np\n",
        "import pygame\n",
        "import random\n",
        "import sys\n",
        "\n",
        "# Konstanta untuk lingkungan grid dan tampilan\n",
        "GRID_WIDTH, GRID_HEIGHT = 10, 10\n",
        "CELL_SIZE = 50\n",
        "SCREEN_WIDTH, SCREEN_HEIGHT = GRID_WIDTH * CELL_SIZE, GRID_HEIGHT * CELL_SIZE\n",
        "\n",
        "# Warna untuk render\n",
        "COLOR_BG = (30, 30, 30)\n",
        "COLOR_GRID = (50, 50, 50)\n",
        "COLOR_AGENT = (0, 255, 0)\n",
        "COLOR_GOAL = (255, 215, 0)\n",
        "COLOR_TRAP = (255, 0, 0)\n",
        "COLOR_ENEMY = (255, 0, 255)\n",
        "\n",
        "# Aksi yang tersedia: 0: Atas, 1: Bawah, 2: Kiri, 3: Kanan\n",
        "ACTION_MAPPING = {\n",
        "    0: (0, -1),\n",
        "    1: (0, 1),\n",
        "    2: (-1, 0),\n",
        "    3: (1, 0)\n",
        "}\n",
        "\n",
        "\n",
        "class AISurvivalEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    Custom Environment untuk AI Survival Quest berbasis grid.\n",
        "    Pemain adalah robot AI yang belajar menghindari jebakan dan musuh untuk mencapai tujuan.\n",
        "    \"\"\"\n",
        "    metadata = {\"render.modes\": [\"human\"]}\n",
        "\n",
        "    def __init__(self):\n",
        "        super(AISurvivalEnv, self).__init__()\n",
        "        # Mendefinisikan ruang aksi dan observasi\n",
        "        self.action_space = spaces.Discrete(4)  # 4 arah\n",
        "        # Observasi hanya posisi (x, y) robot di grid\n",
        "        self.observation_space = spaces.Box(low=0, high=max(GRID_WIDTH, GRID_HEIGHT)-1,\n",
        "                                            shape=(2,), dtype=np.int32)\n",
        "\n",
        "        # Inisialisasi posisi robot, goal, trap, dan musuh\n",
        "        self.agent_pos = np.array([0, 0])\n",
        "        self.goal_pos = np.array([GRID_WIDTH - 1, GRID_HEIGHT - 1])\n",
        "        self.trap_positions = [np.array([3, 3]), np.array([6, 2]), np.array([2, 7])]\n",
        "        self.enemy_positions = [np.array([5, 5])]  # Bisa dikembangkan dengan pola gerak sederhana\n",
        "\n",
        "        self.max_steps = 100  # Batas langkah per episode\n",
        "        self.current_step = 0\n",
        "\n",
        "        # Inisialisasi Pygame untuk render (hanya sekali)\n",
        "        pygame.init()\n",
        "        self.screen = pygame.display.set_mode((SCREEN_WIDTH, SCREEN_HEIGHT))\n",
        "        pygame.display.set_caption(\"AI Survival Quest\")\n",
        "        self.clock = pygame.time.Clock()\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Reset lingkungan ke kondisi awal.\"\"\"\n",
        "        self.agent_pos = np.array([0, 0])\n",
        "        self.current_step = 0\n",
        "        return self._get_obs()\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Implementasi logika pergerakan agent dan reward berdasarkan aksi.\"\"\"\n",
        "        self.current_step += 1\n",
        "\n",
        "        # Hitung pergerakan baru\n",
        "        move = ACTION_MAPPING.get(action, (0, 0))\n",
        "        new_pos = self.agent_pos + np.array(move)\n",
        "\n",
        "        # Cek batas grid\n",
        "        if 0 <= new_pos[0] < GRID_WIDTH and 0 <= new_pos[1] < GRID_HEIGHT:\n",
        "            self.agent_pos = new_pos\n",
        "        else:\n",
        "            # Jika keluar batas, beri penalti\n",
        "            reward = -5\n",
        "            done = True\n",
        "            return self._get_obs(), reward, done, {}\n",
        "\n",
        "        reward = -1  # Biaya langkah untuk mendorong pencarian strategi yang efisien\n",
        "\n",
        "        # Cek kondisi reward atau penalty\n",
        "        if np.array_equal(self.agent_pos, self.goal_pos):\n",
        "            reward = 10  # Mencapai tujuan\n",
        "            done = True\n",
        "        elif any(np.array_equal(self.agent_pos, trap) for trap in self.trap_positions):\n",
        "            reward = -5  # Jebakan\n",
        "            done = True\n",
        "        elif any(np.array_equal(self.agent_pos, enemy) for enemy in self.enemy_positions):\n",
        "            reward = -5  # Terkena musuh\n",
        "            done = True\n",
        "        elif self.current_step >= self.max_steps:\n",
        "            done = True\n",
        "        else:\n",
        "            done = False\n",
        "\n",
        "        return self._get_obs(), reward, done, {}\n",
        "\n",
        "    def _get_obs(self):\n",
        "        \"\"\"Mengembalikan state observasi, yaitu posisi agent.\"\"\"\n",
        "        return self.agent_pos.copy()\n",
        "\n",
        "    def render(self, mode=\"human\"):\n",
        "        \"\"\"Render tampilan lingkungan dengan Pygame.\"\"\"\n",
        "        for event in pygame.event.get():\n",
        "            if event.type == pygame.QUIT:\n",
        "                pygame.quit()\n",
        "                sys.exit()\n",
        "\n",
        "        self.screen.fill(COLOR_BG)\n",
        "        # Gambar grid\n",
        "        for x in range(0, SCREEN_WIDTH, CELL_SIZE):\n",
        "            pygame.draw.line(self.screen, COLOR_GRID, (x, 0), (x, SCREEN_HEIGHT))\n",
        "        for y in range(0, SCREEN_HEIGHT, CELL_SIZE):\n",
        "            pygame.draw.line(self.screen, COLOR_GRID, (0, y), (SCREEN_WIDTH, y))\n",
        "\n",
        "        # Gambar trap\n",
        "        for trap in self.trap_positions:\n",
        "            rect = pygame.Rect(trap[0]*CELL_SIZE, trap[1]*CELL_SIZE, CELL_SIZE, CELL_SIZE)\n",
        "            pygame.draw.rect(self.screen, COLOR_TRAP, rect)\n",
        "\n",
        "        # Gambar musuh\n",
        "        for enemy in self.enemy_positions:\n",
        "            rect = pygame.Rect(enemy[0]*CELL_SIZE, enemy[1]*CELL_SIZE, CELL_SIZE, CELL_SIZE)\n",
        "            pygame.draw.rect(self.screen, COLOR_ENEMY, rect)\n",
        "\n",
        "        # Gambar goal\n",
        "        rect = pygame.Rect(self.goal_pos[0]*CELL_SIZE, self.goal_pos[1]*CELL_SIZE, CELL_SIZE, CELL_SIZE)\n",
        "        pygame.draw.rect(self.screen, COLOR_GOAL, rect)\n",
        "\n",
        "        # Gambar agent\n",
        "        rect = pygame.Rect(self.agent_pos[0]*CELL_SIZE, self.agent_pos[1]*CELL_SIZE, CELL_SIZE, CELL_SIZE)\n",
        "        pygame.draw.rect(self.screen, COLOR_AGENT, rect)\n",
        "\n",
        "        pygame.display.flip()\n",
        "        self.clock.tick(10)\n",
        "\n",
        "    def close(self):\n",
        "        pygame.quit()\n",
        "\n",
        "\n",
        "def choose_action(state, q_table, epsilon):\n",
        "    \"\"\"Pilih aksi menggunakan epsilon-greedy.\"\"\"\n",
        "    if random.uniform(0, 1) < epsilon:\n",
        "        # Eksplorasi: pilih aksi acak\n",
        "        return random.choice(range(4))\n",
        "    else:\n",
        "        # Eksploitasi: pilih aksi dengan nilai Q tertinggi\n",
        "        state_key = tuple(state)\n",
        "        if state_key not in q_table:\n",
        "            q_table[state_key] = np.zeros(4)\n",
        "        return int(np.argmax(q_table[state_key]))\n",
        "\n",
        "\n",
        "def update_q_table(q_table, state, action, reward, next_state, alpha, gamma):\n",
        "    \"\"\"Update Q-table berdasarkan persamaan Q-Learning.\"\"\"\n",
        "    state_key = tuple(state)\n",
        "    next_state_key = tuple(next_state)\n",
        "\n",
        "    if state_key not in q_table:\n",
        "        q_table[state_key] = np.zeros(4)\n",
        "    if next_state_key not in q_table:\n",
        "        q_table[next_state_key] = np.zeros(4)\n",
        "\n",
        "    best_next_action = np.max(q_table[next_state_key])\n",
        "    td_target = reward + gamma * best_next_action\n",
        "    td_error = td_target - q_table[state_key][action]\n",
        "    q_table[state_key][action] += alpha * td_error\n",
        "\n",
        "\n",
        "def main():\n",
        "    env = AISurvivalEnv()\n",
        "    episodes = 500\n",
        "    max_steps = env.max_steps\n",
        "\n",
        "    # Parameter Q-Learning\n",
        "    alpha = 0.1      # Learning rate\n",
        "    gamma = 0.99     # Discount factor\n",
        "    epsilon = 1.0    # Epsilon awal untuk eksplorasi\n",
        "    epsilon_min = 0.01\n",
        "    epsilon_decay = 0.995\n",
        "\n",
        "    # Inisialisasi Q-table sebagai dictionary\n",
        "    q_table = {}\n",
        "\n",
        "    for ep in range(episodes):\n",
        "        state = env.reset()\n",
        "        total_reward = 0\n",
        "\n",
        "        for step in range(max_steps):\n",
        "            action = choose_action(state, q_table, epsilon)\n",
        "            next_state, reward, done, _ = env.step(action)\n",
        "            total_reward += reward\n",
        "\n",
        "            update_q_table(q_table, state, action, reward, next_state, alpha, gamma)\n",
        "            state = next_state\n",
        "\n",
        "            # Render setiap langkah pada episode terakhir untuk visualisasi\n",
        "            if ep >= episodes - 5:\n",
        "                env.render()\n",
        "\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "        # Decay epsilon untuk mengurangi eksplorasi secara bertahap\n",
        "        epsilon = max(epsilon * epsilon_decay, epsilon_min)\n",
        "        print(f\"Episode: {ep+1}, Total Reward: {total_reward}, Epsilon: {epsilon:.3f}\")\n",
        "\n",
        "    # Setelah training, tampilkan hasil akhir\n",
        "    print(\"Training selesai. Tekan CTRL+C pada window render untuk keluar.\")\n",
        "    try:\n",
        "        # Tampilkan episode demo dengan agent yang telah belajar\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "        while not done:\n",
        "            env.render()\n",
        "            action = choose_action(state, q_table, epsilon=0)  # epsilon=0 artinya hanya eksploitasi\n",
        "            state, reward, done, _ = env.step(action)\n",
        "    except KeyboardInterrupt:\n",
        "        env.close()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyQ_lCmJ-jv8",
        "outputId": "66ffa591-4e02-4c72-a0ef-3f9cd362680d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 1, Total Reward: -7, Epsilon: 0.995\n",
            "Episode: 2, Total Reward: -8, Epsilon: 0.990\n",
            "Episode: 3, Total Reward: -5, Epsilon: 0.985\n",
            "Episode: 4, Total Reward: -5, Epsilon: 0.980\n",
            "Episode: 5, Total Reward: -15, Epsilon: 0.975\n",
            "Episode: 6, Total Reward: -5, Epsilon: 0.970\n",
            "Episode: 7, Total Reward: -8, Epsilon: 0.966\n",
            "Episode: 8, Total Reward: -18, Epsilon: 0.961\n",
            "Episode: 9, Total Reward: -7, Epsilon: 0.956\n",
            "Episode: 10, Total Reward: -6, Epsilon: 0.951\n",
            "Episode: 11, Total Reward: -5, Epsilon: 0.946\n",
            "Episode: 12, Total Reward: -11, Epsilon: 0.942\n",
            "Episode: 13, Total Reward: -5, Epsilon: 0.937\n",
            "Episode: 14, Total Reward: -12, Epsilon: 0.932\n",
            "Episode: 15, Total Reward: -9, Epsilon: 0.928\n",
            "Episode: 16, Total Reward: -5, Epsilon: 0.923\n",
            "Episode: 17, Total Reward: -5, Epsilon: 0.918\n",
            "Episode: 18, Total Reward: -7, Epsilon: 0.914\n",
            "Episode: 19, Total Reward: -5, Epsilon: 0.909\n",
            "Episode: 20, Total Reward: -6, Epsilon: 0.905\n",
            "Episode: 21, Total Reward: -6, Epsilon: 0.900\n",
            "Episode: 22, Total Reward: -5, Epsilon: 0.896\n",
            "Episode: 23, Total Reward: -5, Epsilon: 0.891\n",
            "Episode: 24, Total Reward: -5, Epsilon: 0.887\n",
            "Episode: 25, Total Reward: -12, Epsilon: 0.882\n",
            "Episode: 26, Total Reward: -5, Epsilon: 0.878\n",
            "Episode: 27, Total Reward: -5, Epsilon: 0.873\n",
            "Episode: 28, Total Reward: -5, Epsilon: 0.869\n",
            "Episode: 29, Total Reward: -10, Epsilon: 0.865\n",
            "Episode: 30, Total Reward: -7, Epsilon: 0.860\n",
            "Episode: 31, Total Reward: -5, Epsilon: 0.856\n",
            "Episode: 32, Total Reward: -5, Epsilon: 0.852\n",
            "Episode: 33, Total Reward: -6, Epsilon: 0.848\n",
            "Episode: 34, Total Reward: -5, Epsilon: 0.843\n",
            "Episode: 35, Total Reward: -16, Epsilon: 0.839\n",
            "Episode: 36, Total Reward: -23, Epsilon: 0.835\n",
            "Episode: 37, Total Reward: -5, Epsilon: 0.831\n",
            "Episode: 38, Total Reward: -8, Epsilon: 0.827\n",
            "Episode: 39, Total Reward: -12, Epsilon: 0.822\n",
            "Episode: 40, Total Reward: -6, Epsilon: 0.818\n",
            "Episode: 41, Total Reward: -5, Epsilon: 0.814\n",
            "Episode: 42, Total Reward: -5, Epsilon: 0.810\n",
            "Episode: 43, Total Reward: -5, Epsilon: 0.806\n",
            "Episode: 44, Total Reward: -11, Epsilon: 0.802\n",
            "Episode: 45, Total Reward: -5, Epsilon: 0.798\n",
            "Episode: 46, Total Reward: -6, Epsilon: 0.794\n",
            "Episode: 47, Total Reward: -11, Epsilon: 0.790\n",
            "Episode: 48, Total Reward: -5, Epsilon: 0.786\n",
            "Episode: 49, Total Reward: -5, Epsilon: 0.782\n",
            "Episode: 50, Total Reward: -12, Epsilon: 0.778\n",
            "Episode: 51, Total Reward: -6, Epsilon: 0.774\n",
            "Episode: 52, Total Reward: -6, Epsilon: 0.771\n",
            "Episode: 53, Total Reward: -6, Epsilon: 0.767\n",
            "Episode: 54, Total Reward: -5, Epsilon: 0.763\n",
            "Episode: 55, Total Reward: -9, Epsilon: 0.759\n",
            "Episode: 56, Total Reward: -5, Epsilon: 0.755\n",
            "Episode: 57, Total Reward: -7, Epsilon: 0.751\n",
            "Episode: 58, Total Reward: -11, Epsilon: 0.748\n",
            "Episode: 59, Total Reward: -16, Epsilon: 0.744\n",
            "Episode: 60, Total Reward: -11, Epsilon: 0.740\n",
            "Episode: 61, Total Reward: -5, Epsilon: 0.737\n",
            "Episode: 62, Total Reward: -5, Epsilon: 0.733\n",
            "Episode: 63, Total Reward: -22, Epsilon: 0.729\n",
            "Episode: 64, Total Reward: -10, Epsilon: 0.726\n",
            "Episode: 65, Total Reward: -5, Epsilon: 0.722\n",
            "Episode: 66, Total Reward: -19, Epsilon: 0.718\n",
            "Episode: 67, Total Reward: -5, Epsilon: 0.715\n",
            "Episode: 68, Total Reward: -9, Epsilon: 0.711\n",
            "Episode: 69, Total Reward: -6, Epsilon: 0.708\n",
            "Episode: 70, Total Reward: -6, Epsilon: 0.704\n",
            "Episode: 71, Total Reward: -15, Epsilon: 0.701\n",
            "Episode: 72, Total Reward: -9, Epsilon: 0.697\n",
            "Episode: 73, Total Reward: -12, Epsilon: 0.694\n",
            "Episode: 74, Total Reward: -8, Epsilon: 0.690\n",
            "Episode: 75, Total Reward: -8, Epsilon: 0.687\n",
            "Episode: 76, Total Reward: -20, Epsilon: 0.683\n",
            "Episode: 77, Total Reward: -7, Epsilon: 0.680\n",
            "Episode: 78, Total Reward: -6, Epsilon: 0.676\n",
            "Episode: 79, Total Reward: -6, Epsilon: 0.673\n",
            "Episode: 80, Total Reward: -6, Epsilon: 0.670\n",
            "Episode: 81, Total Reward: -22, Epsilon: 0.666\n",
            "Episode: 82, Total Reward: -12, Epsilon: 0.663\n",
            "Episode: 83, Total Reward: -5, Epsilon: 0.660\n",
            "Episode: 84, Total Reward: -17, Epsilon: 0.656\n",
            "Episode: 85, Total Reward: -5, Epsilon: 0.653\n",
            "Episode: 86, Total Reward: -5, Epsilon: 0.650\n",
            "Episode: 87, Total Reward: -11, Epsilon: 0.647\n",
            "Episode: 88, Total Reward: -6, Epsilon: 0.643\n",
            "Episode: 89, Total Reward: -7, Epsilon: 0.640\n",
            "Episode: 90, Total Reward: -5, Epsilon: 0.637\n",
            "Episode: 91, Total Reward: -5, Epsilon: 0.634\n",
            "Episode: 92, Total Reward: -6, Epsilon: 0.631\n",
            "Episode: 93, Total Reward: -5, Epsilon: 0.627\n",
            "Episode: 94, Total Reward: -14, Epsilon: 0.624\n",
            "Episode: 95, Total Reward: -44, Epsilon: 0.621\n",
            "Episode: 96, Total Reward: -53, Epsilon: 0.618\n",
            "Episode: 97, Total Reward: -5, Epsilon: 0.615\n",
            "Episode: 98, Total Reward: -8, Epsilon: 0.612\n",
            "Episode: 99, Total Reward: -5, Epsilon: 0.609\n",
            "Episode: 100, Total Reward: -6, Epsilon: 0.606\n",
            "Episode: 101, Total Reward: -17, Epsilon: 0.603\n",
            "Episode: 102, Total Reward: -23, Epsilon: 0.600\n",
            "Episode: 103, Total Reward: -40, Epsilon: 0.597\n",
            "Episode: 104, Total Reward: -5, Epsilon: 0.594\n",
            "Episode: 105, Total Reward: -18, Epsilon: 0.591\n",
            "Episode: 106, Total Reward: -56, Epsilon: 0.588\n",
            "Episode: 107, Total Reward: -6, Epsilon: 0.585\n",
            "Episode: 108, Total Reward: -30, Epsilon: 0.582\n",
            "Episode: 109, Total Reward: -26, Epsilon: 0.579\n",
            "Episode: 110, Total Reward: -5, Epsilon: 0.576\n",
            "Episode: 111, Total Reward: -5, Epsilon: 0.573\n",
            "Episode: 112, Total Reward: -5, Epsilon: 0.570\n",
            "Episode: 113, Total Reward: -5, Epsilon: 0.568\n",
            "Episode: 114, Total Reward: -5, Epsilon: 0.565\n",
            "Episode: 115, Total Reward: -7, Epsilon: 0.562\n",
            "Episode: 116, Total Reward: -17, Epsilon: 0.559\n",
            "Episode: 117, Total Reward: -5, Epsilon: 0.556\n",
            "Episode: 118, Total Reward: -10, Epsilon: 0.554\n",
            "Episode: 119, Total Reward: -33, Epsilon: 0.551\n",
            "Episode: 120, Total Reward: -5, Epsilon: 0.548\n",
            "Episode: 121, Total Reward: -13, Epsilon: 0.545\n",
            "Episode: 122, Total Reward: -30, Epsilon: 0.543\n",
            "Episode: 123, Total Reward: -40, Epsilon: 0.540\n",
            "Episode: 124, Total Reward: -6, Epsilon: 0.537\n",
            "Episode: 125, Total Reward: -5, Epsilon: 0.534\n",
            "Episode: 126, Total Reward: -5, Epsilon: 0.532\n",
            "Episode: 127, Total Reward: -13, Epsilon: 0.529\n",
            "Episode: 128, Total Reward: -14, Epsilon: 0.526\n",
            "Episode: 129, Total Reward: -5, Epsilon: 0.524\n",
            "Episode: 130, Total Reward: -16, Epsilon: 0.521\n",
            "Episode: 131, Total Reward: -10, Epsilon: 0.519\n",
            "Episode: 132, Total Reward: -5, Epsilon: 0.516\n",
            "Episode: 133, Total Reward: -5, Epsilon: 0.513\n",
            "Episode: 134, Total Reward: -6, Epsilon: 0.511\n",
            "Episode: 135, Total Reward: -5, Epsilon: 0.508\n",
            "Episode: 136, Total Reward: -5, Epsilon: 0.506\n",
            "Episode: 137, Total Reward: -32, Epsilon: 0.503\n",
            "Episode: 138, Total Reward: -7, Epsilon: 0.501\n",
            "Episode: 139, Total Reward: -24, Epsilon: 0.498\n",
            "Episode: 140, Total Reward: -26, Epsilon: 0.496\n",
            "Episode: 141, Total Reward: -22, Epsilon: 0.493\n",
            "Episode: 142, Total Reward: -26, Epsilon: 0.491\n",
            "Episode: 143, Total Reward: -5, Epsilon: 0.488\n",
            "Episode: 144, Total Reward: -22, Epsilon: 0.486\n",
            "Episode: 145, Total Reward: -5, Epsilon: 0.483\n",
            "Episode: 146, Total Reward: -7, Epsilon: 0.481\n",
            "Episode: 147, Total Reward: -8, Epsilon: 0.479\n",
            "Episode: 148, Total Reward: -10, Epsilon: 0.476\n",
            "Episode: 149, Total Reward: -28, Epsilon: 0.474\n",
            "Episode: 150, Total Reward: -31, Epsilon: 0.471\n",
            "Episode: 151, Total Reward: -5, Epsilon: 0.469\n",
            "Episode: 152, Total Reward: -22, Epsilon: 0.467\n",
            "Episode: 153, Total Reward: -22, Epsilon: 0.464\n",
            "Episode: 154, Total Reward: -27, Epsilon: 0.462\n",
            "Episode: 155, Total Reward: -5, Epsilon: 0.460\n",
            "Episode: 156, Total Reward: -6, Epsilon: 0.458\n",
            "Episode: 157, Total Reward: -9, Epsilon: 0.455\n",
            "Episode: 158, Total Reward: -9, Epsilon: 0.453\n",
            "Episode: 159, Total Reward: -27, Epsilon: 0.451\n",
            "Episode: 160, Total Reward: -7, Epsilon: 0.448\n",
            "Episode: 161, Total Reward: -68, Epsilon: 0.446\n",
            "Episode: 162, Total Reward: -6, Epsilon: 0.444\n",
            "Episode: 163, Total Reward: -26, Epsilon: 0.442\n",
            "Episode: 164, Total Reward: -5, Epsilon: 0.440\n",
            "Episode: 165, Total Reward: -12, Epsilon: 0.437\n",
            "Episode: 166, Total Reward: -28, Epsilon: 0.435\n",
            "Episode: 167, Total Reward: -28, Epsilon: 0.433\n",
            "Episode: 168, Total Reward: -15, Epsilon: 0.431\n",
            "Episode: 169, Total Reward: -47, Epsilon: 0.429\n",
            "Episode: 170, Total Reward: -18, Epsilon: 0.427\n",
            "Episode: 171, Total Reward: -5, Epsilon: 0.424\n",
            "Episode: 172, Total Reward: -19, Epsilon: 0.422\n",
            "Episode: 173, Total Reward: -10, Epsilon: 0.420\n",
            "Episode: 174, Total Reward: -10, Epsilon: 0.418\n",
            "Episode: 175, Total Reward: -5, Epsilon: 0.416\n",
            "Episode: 176, Total Reward: -5, Epsilon: 0.414\n",
            "Episode: 177, Total Reward: -16, Epsilon: 0.412\n",
            "Episode: 178, Total Reward: -11, Epsilon: 0.410\n",
            "Episode: 179, Total Reward: -12, Epsilon: 0.408\n",
            "Episode: 180, Total Reward: -36, Epsilon: 0.406\n",
            "Episode: 181, Total Reward: -16, Epsilon: 0.404\n",
            "Episode: 182, Total Reward: -14, Epsilon: 0.402\n",
            "Episode: 183, Total Reward: -5, Epsilon: 0.400\n",
            "Episode: 184, Total Reward: -5, Epsilon: 0.398\n",
            "Episode: 185, Total Reward: -6, Epsilon: 0.396\n",
            "Episode: 186, Total Reward: -30, Epsilon: 0.394\n",
            "Episode: 187, Total Reward: -5, Epsilon: 0.392\n",
            "Episode: 188, Total Reward: -6, Epsilon: 0.390\n",
            "Episode: 189, Total Reward: -45, Epsilon: 0.388\n",
            "Episode: 190, Total Reward: -17, Epsilon: 0.386\n",
            "Episode: 191, Total Reward: -32, Epsilon: 0.384\n",
            "Episode: 192, Total Reward: -5, Epsilon: 0.382\n",
            "Episode: 193, Total Reward: -7, Epsilon: 0.380\n",
            "Episode: 194, Total Reward: -5, Epsilon: 0.378\n",
            "Episode: 195, Total Reward: -89, Epsilon: 0.376\n",
            "Episode: 196, Total Reward: -7, Epsilon: 0.374\n",
            "Episode: 197, Total Reward: -5, Epsilon: 0.373\n",
            "Episode: 198, Total Reward: -14, Epsilon: 0.371\n",
            "Episode: 199, Total Reward: -12, Epsilon: 0.369\n",
            "Episode: 200, Total Reward: -6, Epsilon: 0.367\n",
            "Episode: 201, Total Reward: -7, Epsilon: 0.365\n",
            "Episode: 202, Total Reward: -7, Epsilon: 0.363\n",
            "Episode: 203, Total Reward: -35, Epsilon: 0.361\n",
            "Episode: 204, Total Reward: -6, Epsilon: 0.360\n",
            "Episode: 205, Total Reward: -12, Epsilon: 0.358\n",
            "Episode: 206, Total Reward: -55, Epsilon: 0.356\n",
            "Episode: 207, Total Reward: -12, Epsilon: 0.354\n",
            "Episode: 208, Total Reward: -21, Epsilon: 0.353\n",
            "Episode: 209, Total Reward: -12, Epsilon: 0.351\n",
            "Episode: 210, Total Reward: -6, Epsilon: 0.349\n",
            "Episode: 211, Total Reward: -46, Epsilon: 0.347\n",
            "Episode: 212, Total Reward: -24, Epsilon: 0.346\n",
            "Episode: 213, Total Reward: -35, Epsilon: 0.344\n",
            "Episode: 214, Total Reward: -32, Epsilon: 0.342\n",
            "Episode: 215, Total Reward: -39, Epsilon: 0.340\n",
            "Episode: 216, Total Reward: -7, Epsilon: 0.339\n",
            "Episode: 217, Total Reward: -34, Epsilon: 0.337\n",
            "Episode: 218, Total Reward: -5, Epsilon: 0.335\n",
            "Episode: 219, Total Reward: -6, Epsilon: 0.334\n",
            "Episode: 220, Total Reward: -6, Epsilon: 0.332\n",
            "Episode: 221, Total Reward: -19, Epsilon: 0.330\n",
            "Episode: 222, Total Reward: -9, Epsilon: 0.329\n",
            "Episode: 223, Total Reward: -6, Epsilon: 0.327\n",
            "Episode: 224, Total Reward: -5, Epsilon: 0.325\n",
            "Episode: 225, Total Reward: -7, Epsilon: 0.324\n",
            "Episode: 226, Total Reward: -5, Epsilon: 0.322\n",
            "Episode: 227, Total Reward: -26, Epsilon: 0.321\n",
            "Episode: 228, Total Reward: -5, Epsilon: 0.319\n",
            "Episode: 229, Total Reward: -24, Epsilon: 0.317\n",
            "Episode: 230, Total Reward: -8, Epsilon: 0.316\n",
            "Episode: 231, Total Reward: -6, Epsilon: 0.314\n",
            "Episode: 232, Total Reward: -8, Epsilon: 0.313\n",
            "Episode: 233, Total Reward: -58, Epsilon: 0.311\n",
            "Episode: 234, Total Reward: -55, Epsilon: 0.309\n",
            "Episode: 235, Total Reward: -48, Epsilon: 0.308\n",
            "Episode: 236, Total Reward: -13, Epsilon: 0.306\n",
            "Episode: 237, Total Reward: -41, Epsilon: 0.305\n",
            "Episode: 238, Total Reward: -11, Epsilon: 0.303\n",
            "Episode: 239, Total Reward: -23, Epsilon: 0.302\n",
            "Episode: 240, Total Reward: -52, Epsilon: 0.300\n",
            "Episode: 241, Total Reward: -16, Epsilon: 0.299\n",
            "Episode: 242, Total Reward: -5, Epsilon: 0.297\n",
            "Episode: 243, Total Reward: -6, Epsilon: 0.296\n",
            "Episode: 244, Total Reward: -11, Epsilon: 0.294\n",
            "Episode: 245, Total Reward: -30, Epsilon: 0.293\n",
            "Episode: 246, Total Reward: -24, Epsilon: 0.291\n",
            "Episode: 247, Total Reward: -24, Epsilon: 0.290\n",
            "Episode: 248, Total Reward: -6, Epsilon: 0.288\n",
            "Episode: 249, Total Reward: -16, Epsilon: 0.287\n",
            "Episode: 250, Total Reward: -15, Epsilon: 0.286\n",
            "Episode: 251, Total Reward: -5, Epsilon: 0.284\n",
            "Episode: 252, Total Reward: -36, Epsilon: 0.283\n",
            "Episode: 253, Total Reward: -32, Epsilon: 0.281\n",
            "Episode: 254, Total Reward: -21, Epsilon: 0.280\n",
            "Episode: 255, Total Reward: -7, Epsilon: 0.279\n",
            "Episode: 256, Total Reward: -34, Epsilon: 0.277\n",
            "Episode: 257, Total Reward: -20, Epsilon: 0.276\n",
            "Episode: 258, Total Reward: -5, Epsilon: 0.274\n",
            "Episode: 259, Total Reward: -32, Epsilon: 0.273\n",
            "Episode: 260, Total Reward: -24, Epsilon: 0.272\n",
            "Episode: 261, Total Reward: -17, Epsilon: 0.270\n",
            "Episode: 262, Total Reward: -6, Epsilon: 0.269\n",
            "Episode: 263, Total Reward: -49, Epsilon: 0.268\n",
            "Episode: 264, Total Reward: -14, Epsilon: 0.266\n",
            "Episode: 265, Total Reward: -36, Epsilon: 0.265\n",
            "Episode: 266, Total Reward: -50, Epsilon: 0.264\n",
            "Episode: 267, Total Reward: -16, Epsilon: 0.262\n",
            "Episode: 268, Total Reward: -100, Epsilon: 0.261\n",
            "Episode: 269, Total Reward: -7, Epsilon: 0.260\n",
            "Episode: 270, Total Reward: -14, Epsilon: 0.258\n",
            "Episode: 271, Total Reward: -5, Epsilon: 0.257\n",
            "Episode: 272, Total Reward: -20, Epsilon: 0.256\n",
            "Episode: 273, Total Reward: -21, Epsilon: 0.255\n",
            "Episode: 274, Total Reward: -31, Epsilon: 0.253\n",
            "Episode: 275, Total Reward: -9, Epsilon: 0.252\n",
            "Episode: 276, Total Reward: -32, Epsilon: 0.251\n",
            "Episode: 277, Total Reward: -28, Epsilon: 0.249\n",
            "Episode: 278, Total Reward: -21, Epsilon: 0.248\n",
            "Episode: 279, Total Reward: -5, Epsilon: 0.247\n",
            "Episode: 280, Total Reward: -29, Epsilon: 0.246\n",
            "Episode: 281, Total Reward: -29, Epsilon: 0.245\n",
            "Episode: 282, Total Reward: -11, Epsilon: 0.243\n",
            "Episode: 283, Total Reward: -12, Epsilon: 0.242\n",
            "Episode: 284, Total Reward: -8, Epsilon: 0.241\n",
            "Episode: 285, Total Reward: -39, Epsilon: 0.240\n",
            "Episode: 286, Total Reward: -45, Epsilon: 0.238\n",
            "Episode: 287, Total Reward: -13, Epsilon: 0.237\n",
            "Episode: 288, Total Reward: -22, Epsilon: 0.236\n",
            "Episode: 289, Total Reward: -45, Epsilon: 0.235\n",
            "Episode: 290, Total Reward: -11, Epsilon: 0.234\n",
            "Episode: 291, Total Reward: -28, Epsilon: 0.233\n",
            "Episode: 292, Total Reward: -51, Epsilon: 0.231\n",
            "Episode: 293, Total Reward: -53, Epsilon: 0.230\n",
            "Episode: 294, Total Reward: -7, Epsilon: 0.229\n",
            "Episode: 295, Total Reward: -50, Epsilon: 0.228\n",
            "Episode: 296, Total Reward: -5, Epsilon: 0.227\n",
            "Episode: 297, Total Reward: -41, Epsilon: 0.226\n",
            "Episode: 298, Total Reward: -30, Epsilon: 0.225\n",
            "Episode: 299, Total Reward: -34, Epsilon: 0.223\n",
            "Episode: 300, Total Reward: -6, Epsilon: 0.222\n",
            "Episode: 301, Total Reward: -25, Epsilon: 0.221\n",
            "Episode: 302, Total Reward: -18, Epsilon: 0.220\n",
            "Episode: 303, Total Reward: -22, Epsilon: 0.219\n",
            "Episode: 304, Total Reward: -27, Epsilon: 0.218\n",
            "Episode: 305, Total Reward: -13, Epsilon: 0.217\n",
            "Episode: 306, Total Reward: -16, Epsilon: 0.216\n",
            "Episode: 307, Total Reward: -30, Epsilon: 0.215\n",
            "Episode: 308, Total Reward: -65, Epsilon: 0.214\n",
            "Episode: 309, Total Reward: -12, Epsilon: 0.212\n",
            "Episode: 310, Total Reward: -12, Epsilon: 0.211\n",
            "Episode: 311, Total Reward: -95, Epsilon: 0.210\n",
            "Episode: 312, Total Reward: -44, Epsilon: 0.209\n",
            "Episode: 313, Total Reward: -27, Epsilon: 0.208\n",
            "Episode: 314, Total Reward: -22, Epsilon: 0.207\n",
            "Episode: 315, Total Reward: -49, Epsilon: 0.206\n",
            "Episode: 316, Total Reward: -14, Epsilon: 0.205\n",
            "Episode: 317, Total Reward: -32, Epsilon: 0.204\n",
            "Episode: 318, Total Reward: -6, Epsilon: 0.203\n",
            "Episode: 319, Total Reward: -53, Epsilon: 0.202\n",
            "Episode: 320, Total Reward: -30, Epsilon: 0.201\n",
            "Episode: 321, Total Reward: -46, Epsilon: 0.200\n",
            "Episode: 322, Total Reward: -68, Epsilon: 0.199\n",
            "Episode: 323, Total Reward: -94, Epsilon: 0.198\n",
            "Episode: 324, Total Reward: -9, Epsilon: 0.197\n",
            "Episode: 325, Total Reward: -47, Epsilon: 0.196\n",
            "Episode: 326, Total Reward: -62, Epsilon: 0.195\n",
            "Episode: 327, Total Reward: -26, Epsilon: 0.194\n",
            "Episode: 328, Total Reward: -46, Epsilon: 0.193\n",
            "Episode: 329, Total Reward: -35, Epsilon: 0.192\n",
            "Episode: 330, Total Reward: -38, Epsilon: 0.191\n",
            "Episode: 331, Total Reward: -7, Epsilon: 0.190\n",
            "Episode: 332, Total Reward: -53, Epsilon: 0.189\n",
            "Episode: 333, Total Reward: -6, Epsilon: 0.188\n",
            "Episode: 334, Total Reward: -55, Epsilon: 0.187\n",
            "Episode: 335, Total Reward: -11, Epsilon: 0.187\n",
            "Episode: 336, Total Reward: -24, Epsilon: 0.186\n",
            "Episode: 337, Total Reward: -62, Epsilon: 0.185\n",
            "Episode: 338, Total Reward: -9, Epsilon: 0.184\n",
            "Episode: 339, Total Reward: -17, Epsilon: 0.183\n",
            "Episode: 340, Total Reward: -40, Epsilon: 0.182\n",
            "Episode: 341, Total Reward: -18, Epsilon: 0.181\n",
            "Episode: 342, Total Reward: -20, Epsilon: 0.180\n",
            "Episode: 343, Total Reward: -40, Epsilon: 0.179\n",
            "Episode: 344, Total Reward: -46, Epsilon: 0.178\n",
            "Episode: 345, Total Reward: -23, Epsilon: 0.177\n",
            "Episode: 346, Total Reward: -29, Epsilon: 0.177\n",
            "Episode: 347, Total Reward: -38, Epsilon: 0.176\n",
            "Episode: 348, Total Reward: -32, Epsilon: 0.175\n",
            "Episode: 349, Total Reward: -30, Epsilon: 0.174\n",
            "Episode: 350, Total Reward: -62, Epsilon: 0.173\n",
            "Episode: 351, Total Reward: -37, Epsilon: 0.172\n",
            "Episode: 352, Total Reward: -18, Epsilon: 0.171\n",
            "Episode: 353, Total Reward: -44, Epsilon: 0.170\n",
            "Episode: 354, Total Reward: -41, Epsilon: 0.170\n",
            "Episode: 355, Total Reward: -12, Epsilon: 0.169\n",
            "Episode: 356, Total Reward: -30, Epsilon: 0.168\n",
            "Episode: 357, Total Reward: -19, Epsilon: 0.167\n",
            "Episode: 358, Total Reward: -21, Epsilon: 0.166\n",
            "Episode: 359, Total Reward: -7, Epsilon: 0.165\n",
            "Episode: 360, Total Reward: -28, Epsilon: 0.165\n",
            "Episode: 361, Total Reward: -20, Epsilon: 0.164\n",
            "Episode: 362, Total Reward: -30, Epsilon: 0.163\n",
            "Episode: 363, Total Reward: -25, Epsilon: 0.162\n",
            "Episode: 364, Total Reward: -61, Epsilon: 0.161\n",
            "Episode: 365, Total Reward: -8, Epsilon: 0.160\n",
            "Episode: 366, Total Reward: -50, Epsilon: 0.160\n",
            "Episode: 367, Total Reward: -20, Epsilon: 0.159\n",
            "Episode: 368, Total Reward: -12, Epsilon: 0.158\n",
            "Episode: 369, Total Reward: -8, Epsilon: 0.157\n",
            "Episode: 370, Total Reward: -13, Epsilon: 0.157\n",
            "Episode: 371, Total Reward: -37, Epsilon: 0.156\n",
            "Episode: 372, Total Reward: -7, Epsilon: 0.155\n",
            "Episode: 373, Total Reward: -5, Epsilon: 0.154\n",
            "Episode: 374, Total Reward: -45, Epsilon: 0.153\n",
            "Episode: 375, Total Reward: -5, Epsilon: 0.153\n",
            "Episode: 376, Total Reward: -77, Epsilon: 0.152\n",
            "Episode: 377, Total Reward: -13, Epsilon: 0.151\n",
            "Episode: 378, Total Reward: -10, Epsilon: 0.150\n",
            "Episode: 379, Total Reward: -23, Epsilon: 0.150\n",
            "Episode: 380, Total Reward: -61, Epsilon: 0.149\n",
            "Episode: 381, Total Reward: -8, Epsilon: 0.148\n",
            "Episode: 382, Total Reward: -50, Epsilon: 0.147\n",
            "Episode: 383, Total Reward: -5, Epsilon: 0.147\n",
            "Episode: 384, Total Reward: -69, Epsilon: 0.146\n",
            "Episode: 385, Total Reward: -43, Epsilon: 0.145\n",
            "Episode: 386, Total Reward: -6, Epsilon: 0.144\n",
            "Episode: 387, Total Reward: -11, Epsilon: 0.144\n",
            "Episode: 388, Total Reward: -20, Epsilon: 0.143\n",
            "Episode: 389, Total Reward: -19, Epsilon: 0.142\n",
            "Episode: 390, Total Reward: -13, Epsilon: 0.142\n",
            "Episode: 391, Total Reward: -12, Epsilon: 0.141\n",
            "Episode: 392, Total Reward: -35, Epsilon: 0.140\n",
            "Episode: 393, Total Reward: -13, Epsilon: 0.139\n",
            "Episode: 394, Total Reward: -7, Epsilon: 0.139\n",
            "Episode: 395, Total Reward: -40, Epsilon: 0.138\n",
            "Episode: 396, Total Reward: -45, Epsilon: 0.137\n",
            "Episode: 397, Total Reward: -35, Epsilon: 0.137\n",
            "Episode: 398, Total Reward: -16, Epsilon: 0.136\n",
            "Episode: 399, Total Reward: -7, Epsilon: 0.135\n",
            "Episode: 400, Total Reward: -54, Epsilon: 0.135\n",
            "Episode: 401, Total Reward: -63, Epsilon: 0.134\n",
            "Episode: 402, Total Reward: -14, Epsilon: 0.133\n",
            "Episode: 403, Total Reward: -14, Epsilon: 0.133\n",
            "Episode: 404, Total Reward: -15, Epsilon: 0.132\n",
            "Episode: 405, Total Reward: -24, Epsilon: 0.131\n",
            "Episode: 406, Total Reward: -51, Epsilon: 0.131\n",
            "Episode: 407, Total Reward: -24, Epsilon: 0.130\n",
            "Episode: 408, Total Reward: -5, Epsilon: 0.129\n",
            "Episode: 409, Total Reward: -47, Epsilon: 0.129\n",
            "Episode: 410, Total Reward: -49, Epsilon: 0.128\n",
            "Episode: 411, Total Reward: -44, Epsilon: 0.127\n",
            "Episode: 412, Total Reward: -26, Epsilon: 0.127\n",
            "Episode: 413, Total Reward: -11, Epsilon: 0.126\n",
            "Episode: 414, Total Reward: -32, Epsilon: 0.126\n",
            "Episode: 415, Total Reward: -11, Epsilon: 0.125\n",
            "Episode: 416, Total Reward: -5, Epsilon: 0.124\n",
            "Episode: 417, Total Reward: -16, Epsilon: 0.124\n",
            "Episode: 418, Total Reward: -29, Epsilon: 0.123\n",
            "Episode: 419, Total Reward: -18, Epsilon: 0.122\n",
            "Episode: 420, Total Reward: -7, Epsilon: 0.122\n",
            "Episode: 421, Total Reward: -21, Epsilon: 0.121\n",
            "Episode: 422, Total Reward: -25, Epsilon: 0.121\n",
            "Episode: 423, Total Reward: -7, Epsilon: 0.120\n",
            "Episode: 424, Total Reward: -19, Epsilon: 0.119\n",
            "Episode: 425, Total Reward: -37, Epsilon: 0.119\n",
            "Episode: 426, Total Reward: -26, Epsilon: 0.118\n",
            "Episode: 427, Total Reward: -25, Epsilon: 0.118\n",
            "Episode: 428, Total Reward: -77, Epsilon: 0.117\n",
            "Episode: 429, Total Reward: -10, Epsilon: 0.116\n",
            "Episode: 430, Total Reward: -46, Epsilon: 0.116\n",
            "Episode: 431, Total Reward: -18, Epsilon: 0.115\n",
            "Episode: 432, Total Reward: -82, Epsilon: 0.115\n",
            "Episode: 433, Total Reward: -39, Epsilon: 0.114\n",
            "Episode: 434, Total Reward: -32, Epsilon: 0.114\n",
            "Episode: 435, Total Reward: -24, Epsilon: 0.113\n",
            "Episode: 436, Total Reward: -20, Epsilon: 0.112\n",
            "Episode: 437, Total Reward: -13, Epsilon: 0.112\n",
            "Episode: 438, Total Reward: -18, Epsilon: 0.111\n",
            "Episode: 439, Total Reward: -8, Epsilon: 0.111\n",
            "Episode: 440, Total Reward: -10, Epsilon: 0.110\n",
            "Episode: 441, Total Reward: -17, Epsilon: 0.110\n",
            "Episode: 442, Total Reward: -23, Epsilon: 0.109\n",
            "Episode: 443, Total Reward: -25, Epsilon: 0.109\n",
            "Episode: 444, Total Reward: -38, Epsilon: 0.108\n",
            "Episode: 445, Total Reward: -27, Epsilon: 0.107\n",
            "Episode: 446, Total Reward: -10, Epsilon: 0.107\n",
            "Episode: 447, Total Reward: -29, Epsilon: 0.106\n",
            "Episode: 448, Total Reward: -27, Epsilon: 0.106\n",
            "Episode: 449, Total Reward: -54, Epsilon: 0.105\n",
            "Episode: 450, Total Reward: -53, Epsilon: 0.105\n",
            "Episode: 451, Total Reward: -14, Epsilon: 0.104\n",
            "Episode: 452, Total Reward: -17, Epsilon: 0.104\n",
            "Episode: 453, Total Reward: -27, Epsilon: 0.103\n",
            "Episode: 454, Total Reward: -9, Epsilon: 0.103\n",
            "Episode: 455, Total Reward: -48, Epsilon: 0.102\n",
            "Episode: 456, Total Reward: -63, Epsilon: 0.102\n",
            "Episode: 457, Total Reward: -20, Epsilon: 0.101\n",
            "Episode: 458, Total Reward: -25, Epsilon: 0.101\n",
            "Episode: 459, Total Reward: -39, Epsilon: 0.100\n",
            "Episode: 460, Total Reward: -45, Epsilon: 0.100\n",
            "Episode: 461, Total Reward: -9, Epsilon: 0.099\n",
            "Episode: 462, Total Reward: -18, Epsilon: 0.099\n",
            "Episode: 463, Total Reward: -58, Epsilon: 0.098\n",
            "Episode: 464, Total Reward: -22, Epsilon: 0.098\n",
            "Episode: 465, Total Reward: -24, Epsilon: 0.097\n",
            "Episode: 466, Total Reward: -14, Epsilon: 0.097\n",
            "Episode: 467, Total Reward: -31, Epsilon: 0.096\n",
            "Episode: 468, Total Reward: -42, Epsilon: 0.096\n",
            "Episode: 469, Total Reward: -15, Epsilon: 0.095\n",
            "Episode: 470, Total Reward: -7, Epsilon: 0.095\n",
            "Episode: 471, Total Reward: -35, Epsilon: 0.094\n",
            "Episode: 472, Total Reward: -27, Epsilon: 0.094\n",
            "Episode: 473, Total Reward: -15, Epsilon: 0.093\n",
            "Episode: 474, Total Reward: -34, Epsilon: 0.093\n",
            "Episode: 475, Total Reward: -19, Epsilon: 0.092\n",
            "Episode: 476, Total Reward: -5, Epsilon: 0.092\n",
            "Episode: 477, Total Reward: -33, Epsilon: 0.092\n",
            "Episode: 478, Total Reward: -35, Epsilon: 0.091\n",
            "Episode: 479, Total Reward: -58, Epsilon: 0.091\n",
            "Episode: 480, Total Reward: -29, Epsilon: 0.090\n",
            "Episode: 481, Total Reward: -41, Epsilon: 0.090\n",
            "Episode: 482, Total Reward: -20, Epsilon: 0.089\n",
            "Episode: 483, Total Reward: -8, Epsilon: 0.089\n",
            "Episode: 484, Total Reward: -5, Epsilon: 0.088\n",
            "Episode: 485, Total Reward: -26, Epsilon: 0.088\n",
            "Episode: 486, Total Reward: -33, Epsilon: 0.088\n",
            "Episode: 487, Total Reward: -13, Epsilon: 0.087\n",
            "Episode: 488, Total Reward: -13, Epsilon: 0.087\n",
            "Episode: 489, Total Reward: -5, Epsilon: 0.086\n",
            "Episode: 490, Total Reward: -14, Epsilon: 0.086\n",
            "Episode: 491, Total Reward: -16, Epsilon: 0.085\n",
            "Episode: 492, Total Reward: -19, Epsilon: 0.085\n",
            "Episode: 493, Total Reward: -12, Epsilon: 0.084\n",
            "Episode: 494, Total Reward: -18, Epsilon: 0.084\n",
            "Episode: 495, Total Reward: -8, Epsilon: 0.084\n",
            "Episode: 496, Total Reward: -61, Epsilon: 0.083\n",
            "Episode: 497, Total Reward: -11, Epsilon: 0.083\n",
            "Episode: 498, Total Reward: -22, Epsilon: 0.082\n",
            "Episode: 499, Total Reward: -5, Epsilon: 0.082\n",
            "Episode: 500, Total Reward: -33, Epsilon: 0.082\n",
            "Training selesai. Tekan CTRL+C pada window render untuk keluar.\n"
          ]
        }
      ]
    }
  ]
}